{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convolutional Neural Networks (CNN) use the convolutional layer to extract features given an input. The output shape of the convolution is affected by the shape of the kernel, whether zero padding and strides is applied. This short tutorial illustrates such issues via pytorch examples.\n",
    "\n",
    "**See**. V. Dumoulin and F. Visin, <i>A guide to convolution arithmetic for deep learning</i> <b>2016</b>. doi: 10.48550/ARXIV.1603.07285."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.2813, -0.7602,  0.4495,  1.2502, -0.9426],\n",
       "        [ 0.0784, -1.4935, -0.2362, -0.3786,  0.9867],\n",
       "        [-0.0498, -0.3142,  0.1057,  0.2097,  0.9843],\n",
       "        [-0.6823, -0.4586, -0.1509,  0.4517, -0.6122],\n",
       "        [ 0.7627,  0.1686, -0.9021,  0.4643, -0.2864],\n",
       "        [-0.2242, -2.1846, -0.7038, -0.1789, -0.2455],\n",
       "        [-0.4982, -1.6962,  1.6620, -0.2756,  0.9716],\n",
       "        [ 1.0995,  1.8333, -0.3567,  0.6955, -0.5738],\n",
       "        [-0.2587,  0.2063, -0.6878, -0.7413,  1.2303],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]], requires_grad=True)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First let’s create a fixed size inverted index. Each line corresponds to a words embedding\n",
    "# \n",
    "# padding_idx is a reserved word that is used as wildcard when an unknown word occurs in text.\n",
    "embedding = torch.nn.Embedding(10, 5, padding_idx=9)\n",
    "embedding.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 1.,  1.,  1.,  1.,  1.],\n",
       "        [ 2.,  2.,  2.,  2.,  2.],\n",
       "        [ 3.,  3.,  3.,  3.,  3.],\n",
       "        [ 4.,  4.,  4.,  4.,  4.],\n",
       "        [ 5.,  5.,  5.,  5.,  5.],\n",
       "        [ 6.,  6.,  6.,  6.,  6.],\n",
       "        [ 7.,  7.,  7.,  7.,  7.],\n",
       "        [ 8.,  8.,  8.,  8.,  8.],\n",
       "        [ 9.,  9.,  9.,  9.,  9.],\n",
       "        [10., 10., 10., 10., 10.]], grad_fn=<CopySlices>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For debuggin purposes lets ,make \n",
    "for i in range(1,11):\n",
    "    embedding.weight[i-1,:] = i\n",
    "embedding.weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1D Convolution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2., 3., 4.],\n",
      "        [2., 3., 4.],\n",
      "        [2., 3., 4.],\n",
      "        [2., 3., 4.],\n",
      "        [2., 3., 4.]], grad_fn=<TransposeBackward0>)\n",
      "torch.Size([5, 3])\n"
     ]
    }
   ],
   "source": [
    "# Assume a sequence of words labeled as integers, i.e. [1,2,3]. The invertex\n",
    "# index is used transform each integer to its vector form\n",
    "_1DT = embedding(torch.tensor([1, 2, 3]))\n",
    "\n",
    "# Estimate the transpose\n",
    "_1DT = torch.transpose(embedding(torch.tensor([1, 2, 3])),0,1)\n",
    "print(_1DT)\n",
    "\n",
    "# The tensor shape\n",
    "print(_1DT.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[25., 35.]]], grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1-D Zero padding, unit stride (on one dimension), 1 input/output channel\n",
    "# The convolution output is defined as o = ( i - k ) + 1\n",
    "\n",
    "# let i be the text length\n",
    "# Let d be the number of input channels. In our case, it corresponds to the embedding dimension.\n",
    "# Let r be the number of output channels. For each channel a kernel of size h is created. Each with different coefficients\n",
    "# Let h be the size of the kernel.\n",
    "# Let s be the stride.\n",
    "\n",
    "q = _1DT.shape[0]\n",
    "r = 1\n",
    "h = 2\n",
    "s = 1\n",
    "\n",
    "conv = torch.nn.Conv1d(in_channels=q, out_channels=r, kernel_size=h, stride=s,  bias=False)\n",
    "\n",
    "# To make the convolution effect more visual. Bias terms are disabled from Conv1d and weight \n",
    "# coeficients are made 1 as follows\n",
    "with torch.no_grad():\n",
    "    conv.weight[:,:,:] = 1.\n",
    "\n",
    "# \n",
    "conv(_1DT.unsqueeze(0))\n",
    "    \n",
    "# Shure enough the convolution produced the expected output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6])\n",
      "torch.Size([1, 1, 6])\n",
      "The weight matrix weights are  Parameter containing:\n",
      "tensor([[[1., 1., 1.]]], requires_grad=True)\n",
      "Result :  tensor([[[ 6.,  9., 12., 15.]]], grad_fn=<SqueezeBackward1>)\n"
     ]
    }
   ],
   "source": [
    "# 1-D convolution\n",
    "# in_channels (d), correspon to the embedding dimension.\n",
    "# out_channels (r), the number of kernels that are applied.\n",
    "# kernel_size (h)\n",
    "# stride (s)\n",
    "\n",
    "\n",
    "conv = torch.nn.Conv1d(in_channels=5, out_channels=1, kernel_size=2, stride=1,  bias=False)\n",
    "\n",
    "\n",
    "#T_1D = torch.tensor([1, 2, 3, 4, 5, 6], dtype = torch.float)\n",
    "#print(T_1D.shape)\n",
    "\n",
    "# El tensor debe ser transformado a una matriz donde:\n",
    "# - la primera columna corresponda al número de canales de entrada\n",
    "# - la segunda columna corresponda al número de canales de salida\n",
    "# - la tercera columna corresponda al tamaño de la señal \n",
    "T_1D = T_1D.unsqueeze(0).unsqueeze(0)\n",
    "print(T_1D.shape)\n",
    "\n",
    "# En este ejemplo, aplico un núcleo de tamaño 3. Hize que el número de salidas\n",
    "# sea igual a 1. Si el número de canales de salida es 3, internamente se crean \n",
    "# tres kernels los cuales se aplican durante la fase de convolución.\n",
    "conv = torch.nn.Conv1d(in_channels=1, out_channels=1, kernel_size=3, stride=1,  bias=False)\n",
    "\n",
    "# Para propósito de debug. Inicializo la matriz cero a unos. Si el número de \n",
    "# canales es mayor que 1. Entocnes es necesario inicializar las matrices de \n",
    "# coeficientes adicionales que se crean.\n",
    "with torch.no_grad():\n",
    "    conv.weight[0,:,:] = 1.\n",
    "\n",
    "# Se imprime los coeficientes de la primera matriz.\n",
    "print(\"The weight matrix weights are \", conv.weight)\n",
    "\n",
    "# Se aplica la convolución y se imprime los coeficientes resultantes.\n",
    "print(\"Result : \", conv(T_1D))\n",
    "\n",
    "# Every thing worked as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El contenido del tensor es :  tensor([[[1., 1., 1., 1., 1.],\n",
      "         [2., 2., 2., 2., 2.],\n",
      "         [3., 3., 3., 3., 3.],\n",
      "         [4., 4., 4., 4., 4.]]])\n",
      "La dimensión del tensor es :  torch.Size([1, 4, 5])\n",
      "The weight matrix weights are  Parameter containing:\n",
      "tensor([[[1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1.]]], requires_grad=True)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size 1 5 5, expected input[1, 4, 5] to have 5 channels, but got 4 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-53-9391183e60a9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;31m# Se aplica la convolución y se imprime los coeficientes resultantes.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Result : \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mT_2D\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\nlp\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\nlp\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    199\u001b[0m                             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m                             _single(0), self.dilation, self.groups)\n\u001b[1;32m--> 201\u001b[1;33m         return F.conv1d(input, self.weight, self.bias, self.stride,\n\u001b[0m\u001b[0;32m    202\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[0;32m    203\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Given groups=1, weight of size 1 5 5, expected input[1, 4, 5] to have 5 channels, but got 4 channels instead"
     ]
    }
   ],
   "source": [
    "# 2-D tensor + convolution\n",
    "T_2D = torch.tensor([\n",
    "    [1,1,1,1,1],\n",
    "    [2,2,2,2,2],\n",
    "    [3,3,3,3,3],\n",
    "    [4,4,4,4,4]\n",
    "], dtype = torch.float)\n",
    "\n",
    "\n",
    "# El tensor debe ser transformado a una matriz donde:\n",
    "# - la primera columna corresponda al número de canales de entrada (tamaño del embedding)\n",
    "# - la segunda columna corresponda al número de canales de salida (el número de núcleos)\n",
    "# - la tercera columna corresponda al tamaño de la señal \n",
    "T_2D = T_2D.unsqueeze(0)\n",
    "print(\"El contenido del tensor es : \", T_2D)\n",
    "print(\"La dimensión del tensor es : \", T_2D.shape)\n",
    "\n",
    "# En este ejemplo. Cada canal representa una palabra codificada en su forma vectorial\n",
    "# Deseo un kernel bidimensional unitario con un stride de 1 \n",
    "conv = torch.nn.Conv1d(in_channels=5, out_channels=1, kernel_size=5, stride=1,  bias=False)\n",
    "\n",
    "# Para propósito de debug. Inicializo la matriz cero a unos. Si el número de \n",
    "# canales es mayor que 1. Entocnes es necesario inicializar las matrices de \n",
    "# coeficientes adicionales que se crean.\n",
    "with torch.no_grad():\n",
    "    conv.weight[:,:,:] = 1.\n",
    "\n",
    "# Se imprime los coeficientes de la primera matriz.\n",
    "print(\"The weight matrix weights are \", conv.weight)\n",
    "\n",
    "# Se aplica la convolución y se imprime los coeficientes resultantes.\n",
    "print(\"Result : \", conv(T_2D))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 1., 0., 1., 1.],\n",
       "         [2., 2., 0., 2., 2.],\n",
       "         [3., 3., 0., 3., 3.],\n",
       "         [4., 4., 0., 4., 4.],\n",
       "         [5., 5., 0., 5., 5.]],\n",
       "\n",
       "        [[1., 0., 1., 0., 1.],\n",
       "         [2., 0., 2., 0., 2.],\n",
       "         [3., 0., 3., 0., 3.],\n",
       "         [4., 0., 4., 0., 4.],\n",
       "         [5., 0., 5., 0., 5.]],\n",
       "\n",
       "        [[0., 1., 0., 1., 0.],\n",
       "         [0., 2., 0., 2., 0.],\n",
       "         [0., 3., 0., 3., 0.],\n",
       "         [0., 4., 0., 4., 0.],\n",
       "         [0., 5., 0., 5., 0.]]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2-D tensor, 3 channels\n",
    "T_2D = torch.tensor([  \n",
    "    [[1,1,0,1,1],[2,2,0,2,2],[3,3,0,3,3],[4,4,0,4,4],[5,5,0,5,5]], \n",
    "    [[1,0,1,0,1],[2,0,2,0,2],[3,0,3,0,3],[4,0,4,0,4],[5,0,5,0,5]],\n",
    "    [[0,1,0,1,0],[0,2,0,2,0],[0,3,0,3,0],[0,4,0,4,0],[0,5,0,5,0]]\n",
    "], dtype = torch.float)\n",
    "T_2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
