{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convolutional Neural Networks (CNN) use the convolutional layer to extract features given an input. The output shape of the convolution is affected by the shape of the kernel, whether zero padding and strides is applied. This short tutorial illustrates such issues via pytorch examples.\n",
    "\n",
    "**See**. V. Dumoulin and F. Visin, <i>A guide to convolution arithmetic for deep learning</i> <b>2016</b>. doi: 10.48550/ARXIV.1603.07285."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 1.1468, -0.4076, -1.3490,  1.3407, -0.4617],\n",
       "        [ 0.2554, -0.4200, -0.9022, -0.3080, -1.4300],\n",
       "        [-0.2234,  1.1453,  3.5321, -0.7680,  0.5610],\n",
       "        [ 1.9435,  0.8450,  0.8677,  2.0463, -0.6149],\n",
       "        [-1.2287, -0.9967,  0.4377,  0.2498, -2.8136],\n",
       "        [-0.1270,  0.5649, -0.6316, -0.6323,  0.1887],\n",
       "        [ 1.6070,  0.8327, -1.4601,  0.7082,  1.0071],\n",
       "        [ 0.2133,  2.2039, -0.5650,  0.2053,  0.1076],\n",
       "        [ 0.4367,  1.4659, -0.4419, -0.5802,  1.8514],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]], requires_grad=True)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First let’s create a fixed size inverted index. Each line corresponds to a words embedding\n",
    "# \n",
    "# padding_idx is a reserved word that is used as wildcard when an unknown word occurs in text.\n",
    "embedding = torch.nn.Embedding(10, 5, padding_idx=9)\n",
    "embedding.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 1.,  1.,  1.,  1.,  1.],\n",
       "        [ 2.,  2.,  2.,  2.,  2.],\n",
       "        [ 3.,  3.,  3.,  3.,  3.],\n",
       "        [ 4.,  4.,  4.,  4.,  4.],\n",
       "        [ 5.,  5.,  5.,  5.,  5.],\n",
       "        [ 6.,  6.,  6.,  6.,  6.],\n",
       "        [ 7.,  7.,  7.,  7.,  7.],\n",
       "        [ 8.,  8.,  8.,  8.,  8.],\n",
       "        [ 9.,  9.,  9.,  9.,  9.],\n",
       "        [10., 10., 10., 10., 10.]], grad_fn=<CopySlices>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For debuggin purposes I'll create a synthetic embedding table \n",
    "for i in range(1,11):\n",
    "    embedding.weight[i-1,:] = i\n",
    "embedding.weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1D Convolution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2., 3., 4.],\n",
      "        [2., 3., 4.],\n",
      "        [2., 3., 4.],\n",
      "        [2., 3., 4.],\n",
      "        [2., 3., 4.]], grad_fn=<TransposeBackward0>)\n",
      "torch.Size([5, 3])\n"
     ]
    }
   ],
   "source": [
    "# Assume a sequence of words labeled as integers, i.e. [1,2,3]. The invertex\n",
    "# index is used transform each integer to its vector form\n",
    "_1DT = embedding(torch.tensor([1, 2, 3]))\n",
    "\n",
    "# Estimate the transpose\n",
    "_1DT = torch.transpose(embedding(torch.tensor([1, 2, 3])),0,1)\n",
    "print(_1DT)\n",
    "\n",
    "# The tensor shape\n",
    "print(_1DT.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[25., 35.]]], grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1-D Zero padding, unit stride (on one dimension), 1 input/output channel\n",
    "# The convolution output is defined as o = ( i - k ) + 1\n",
    "\n",
    "# Let d be the number of input channels. In our case, the embedding dimension.\n",
    "# Let r be the number of output channels. For each channel a kernel of size h is created. Each with different coefficients\n",
    "# Let h be the size of the kernel.\n",
    "# Let s be the stride.\n",
    "\n",
    "d = _1DT.shape[0]\n",
    "r = 1\n",
    "h = 2\n",
    "s = 1\n",
    "\n",
    "conv = torch.nn.Conv1d(in_channels=d, out_channels=r, kernel_size=h, stride=s,  bias=False)\n",
    "\n",
    "# To make the convolution effect more visual. Bias terms are disabled from Conv1d and weight \n",
    "# coeficients are made 1 as follows\n",
    "with torch.no_grad():\n",
    "    conv.weight[:,:,:] = 1.\n",
    "\n",
    "# \n",
    "conv(_1DT.unsqueeze(0))\n",
    "    \n",
    "# Shure enough the convolution produced the expected output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets assume two texts of different lengths. The first is padded so that the both have equal lenght."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 1.,  2.,  3., 10., 10.],\n",
      "         [ 1.,  2.,  3., 10., 10.],\n",
      "         [ 1.,  2.,  3., 10., 10.],\n",
      "         [ 1.,  2.,  3., 10., 10.],\n",
      "         [ 1.,  2.,  3., 10., 10.]],\n",
      "\n",
      "        [[ 4.,  5.,  6.,  8.,  9.],\n",
      "         [ 4.,  5.,  6.,  8.,  9.],\n",
      "         [ 4.,  5.,  6.,  8.,  9.],\n",
      "         [ 4.,  5.,  6.,  8.,  9.],\n",
      "         [ 4.,  5.,  6.,  8.,  9.]]], grad_fn=<TransposeBackward0>)\n",
      "torch.Size([2, 5, 5])\n"
     ]
    }
   ],
   "source": [
    "# Assume a sequence of words labeled as integers, i.e. [1,2,3]. The invertex\n",
    "# index is used transform each integer to its vector form\n",
    "_2DT = embedding(torch.tensor([ [0, 1, 2, 9, 9],\n",
    "                                [3, 4, 5, 7, 8] ]))\n",
    "# Estimate the transpose\n",
    "_2DT = torch.transpose(_2DT,1,2)\n",
    "print(_1DT)\n",
    "\n",
    "# The tensor shape\n",
    "print(_2DT.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The weight matrix weights are  Parameter containing:\n",
      "tensor([[[1., 1.],\n",
      "         [1., 1.],\n",
      "         [1., 1.],\n",
      "         [1., 1.],\n",
      "         [1., 1.]]], requires_grad=True)\n",
      "Result :  tensor([[[ 15.,  25.,  65., 100.]],\n",
      "\n",
      "        [[ 45.,  55.,  70.,  85.]]], grad_fn=<SqueezeBackward1>)\n"
     ]
    }
   ],
   "source": [
    "conv = torch.nn.Conv1d(in_channels=5, out_channels=1, kernel_size=2, stride=1,  bias=False)\n",
    "\n",
    "# Para propósito de debug. Inicializo la matriz cero a unos. Si el número de \n",
    "# canales es mayor que 1. Entocnes es necesario inicializar las matrices de \n",
    "# coeficientes adicionales que se crean.\n",
    "with torch.no_grad():\n",
    "    conv.weight[0,:,:] = 1.\n",
    "\n",
    "# Se imprime los coeficientes de la primera matriz.\n",
    "print(\"The weight matrix weights are \", conv.weight)\n",
    "\n",
    "# Se aplica la convolución y se imprime los coeficientes resultantes.\n",
    "print(\"Result : \", conv(_2DT))\n",
    "\n",
    "# Every thing worked as expected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Max polling provides invariance to small translations of a given input. It reduce the size\n",
    "of feature maps by using some function to summarize subregions, such as taking the average or the maximum value. Let test it out. First, lets take the maximum value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kernel_size, the size of the sliding window.\n",
    "# stride, the stride of the sliding window, must be > 0. Default value is kernel_size.\n",
    "# padding, Implicit negative infinity padding to be added on both sides, must be >= 0 and <= kernel_size / 2.\n",
    "nn.MaxPool1d("
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (nlp)",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
