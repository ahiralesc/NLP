{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ref. V. Dumoulin and F. Visin, <i>A guide to convolution arithmetic for deep learning</i> <b>2016</b>. doi: 10.48550/ARXIV.1603.07285."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.5619, -0.7912, -1.9860,  0.4270, -1.6669],\n",
       "        [-0.7633, -1.2504,  0.8393, -0.4949,  0.1892],\n",
       "        [-0.8731, -0.7966, -0.5558,  0.1839, -1.2145],\n",
       "        [-0.4237,  0.2841,  1.3995, -0.6623,  0.8048],\n",
       "        [-0.5552, -0.9208, -1.4534, -0.8995,  0.8469],\n",
       "        [-0.3159, -0.7477, -1.0075,  0.0575, -0.3975],\n",
       "        [-0.9175,  0.3233, -0.8610,  1.1140,  2.1137],\n",
       "        [ 0.9275, -0.4747, -0.2126,  0.8270, -0.5752],\n",
       "        [ 0.6023,  0.4754, -0.6525,  0.5913,  1.3907],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]], requires_grad=True)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generación de un indice invertido. Cada línea en el indice representa\n",
    "# una palabra (vector semantico)\n",
    "# \n",
    "# La variable padding_idx es reservada como comodin para el caso de \n",
    "# que esta sea utilizada como relleno.\n",
    "embedding = torch.nn.Embedding(10, 5, padding_idx=9)\n",
    "embedding.weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejemplo de un tensor 1D**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.7633, -0.8731, -0.4237],\n",
       "        [-1.2504, -0.7966,  0.2841],\n",
       "        [ 0.8393, -0.5558,  1.3995],\n",
       "        [-0.4949,  0.1839, -0.6623],\n",
       "        [ 0.1892, -1.2145,  0.8048]], grad_fn=<TransposeBackward0>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Suponga una secuencia de palabras donde cada palabra es reemplazada por un \n",
    "# índice entero. Sea [1,2,3] tal secuencia. Cada índice de la secuencia es \n",
    "# transformado a su equivalente vectorial. \n",
    "sequence = embedding(torch.tensor([1, 2, 3]))\n",
    "\n",
    "# Aplicación de la transpuesta a la secuencia\n",
    "sequence = torch.transpose(embedding(torch.tensor([1, 2, 3])),0,1)\n",
    "sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6])\n",
      "torch.Size([1, 1, 6])\n",
      "The weight matrix weights are  Parameter containing:\n",
      "tensor([[[1., 1., 1.]]], requires_grad=True)\n",
      "Result :  tensor([[[ 6.,  9., 12., 15.]]], grad_fn=<SqueezeBackward1>)\n"
     ]
    }
   ],
   "source": [
    "# 1-D tensor + convolución\n",
    "\n",
    "T_1D = torch.tensor([1, 2, 3, 4, 5, 6], dtype = torch.float)\n",
    "print(T_1D.shape)\n",
    "\n",
    "# El tensor debe ser transformado a una matriz donde:\n",
    "# - la primera columna corresponda al número de canales de entrada\n",
    "# - la segunda columna corresponda al número de canales de salida\n",
    "# - la tercera columna corresponda al tamaño de la señal \n",
    "T_1D = T_1D.unsqueeze(0).unsqueeze(0)\n",
    "print(T_1D.shape)\n",
    "\n",
    "# En este ejemplo, aplico un núcleo de tamaño 3. Hize que el número de salidas\n",
    "# sea igual a 1. Si el número de canales de salida es 3, internamente se crean \n",
    "# tres kernels los cuales se aplican durante la fase de convolución.\n",
    "conv = torch.nn.Conv1d(in_channels=1, out_channels=1, kernel_size=3, stride=1,  bias=False)\n",
    "\n",
    "# Para propósito de debug. Inicializo la matriz cero a unos. Si el número de \n",
    "# canales es mayor que 1. Entocnes es necesario inicializar las matrices de \n",
    "# coeficientes adicionales que se crean.\n",
    "with torch.no_grad():\n",
    "    conv.weight[0,:,:] = 1.\n",
    "\n",
    "# Se imprime los coeficientes de la primera matriz.\n",
    "print(\"The weight matrix weights are \", conv.weight)\n",
    "\n",
    "# Se aplica la convolución y se imprime los coeficientes resultantes.\n",
    "print(\"Result : \", conv(T_1D))\n",
    "\n",
    "# Every thing worked as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El contenido del tensor es :  tensor([[[1., 1., 1., 1., 1.],\n",
      "         [2., 2., 2., 2., 2.],\n",
      "         [3., 3., 3., 3., 3.],\n",
      "         [4., 4., 4., 4., 4.]]])\n",
      "La dimensión del tensor es :  torch.Size([1, 4, 5])\n",
      "The weight matrix weights are  Parameter containing:\n",
      "tensor([[[1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1.]]], requires_grad=True)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size 1 5 5, expected input[1, 4, 5] to have 5 channels, but got 4 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-53-9391183e60a9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;31m# Se aplica la convolución y se imprime los coeficientes resultantes.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Result : \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mT_2D\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\nlp\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\nlp\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    199\u001b[0m                             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m                             _single(0), self.dilation, self.groups)\n\u001b[1;32m--> 201\u001b[1;33m         return F.conv1d(input, self.weight, self.bias, self.stride,\n\u001b[0m\u001b[0;32m    202\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[0;32m    203\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Given groups=1, weight of size 1 5 5, expected input[1, 4, 5] to have 5 channels, but got 4 channels instead"
     ]
    }
   ],
   "source": [
    "# 2-D tensor + convolution\n",
    "T_2D = torch.tensor([\n",
    "    [1,1,1,1,1],\n",
    "    [2,2,2,2,2],\n",
    "    [3,3,3,3,3],\n",
    "    [4,4,4,4,4]\n",
    "], dtype = torch.float)\n",
    "\n",
    "\n",
    "# El tensor debe ser transformado a una matriz donde:\n",
    "# - la primera columna corresponda al número de canales de entrada (tamaño del embedding)\n",
    "# - la segunda columna corresponda al número de canales de salida (el número de núcleos)\n",
    "# - la tercera columna corresponda al tamaño de la señal \n",
    "T_2D = T_2D.unsqueeze(0)\n",
    "print(\"El contenido del tensor es : \", T_2D)\n",
    "print(\"La dimensión del tensor es : \", T_2D.shape)\n",
    "\n",
    "# En este ejemplo. Cada canal representa una palabra codificada en su forma vectorial\n",
    "# Deseo un kernel bidimensional unitario con un stride de 1 \n",
    "conv = torch.nn.Conv1d(in_channels=5, out_channels=1, kernel_size=5, stride=1,  bias=False)\n",
    "\n",
    "# Para propósito de debug. Inicializo la matriz cero a unos. Si el número de \n",
    "# canales es mayor que 1. Entocnes es necesario inicializar las matrices de \n",
    "# coeficientes adicionales que se crean.\n",
    "with torch.no_grad():\n",
    "    conv.weight[:,:,:] = 1.\n",
    "\n",
    "# Se imprime los coeficientes de la primera matriz.\n",
    "print(\"The weight matrix weights are \", conv.weight)\n",
    "\n",
    "# Se aplica la convolución y se imprime los coeficientes resultantes.\n",
    "print(\"Result : \", conv(T_2D))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 1., 0., 1., 1.],\n",
       "         [2., 2., 0., 2., 2.],\n",
       "         [3., 3., 0., 3., 3.],\n",
       "         [4., 4., 0., 4., 4.],\n",
       "         [5., 5., 0., 5., 5.]],\n",
       "\n",
       "        [[1., 0., 1., 0., 1.],\n",
       "         [2., 0., 2., 0., 2.],\n",
       "         [3., 0., 3., 0., 3.],\n",
       "         [4., 0., 4., 0., 4.],\n",
       "         [5., 0., 5., 0., 5.]],\n",
       "\n",
       "        [[0., 1., 0., 1., 0.],\n",
       "         [0., 2., 0., 2., 0.],\n",
       "         [0., 3., 0., 3., 0.],\n",
       "         [0., 4., 0., 4., 0.],\n",
       "         [0., 5., 0., 5., 0.]]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2-D tensor, 3 channels\n",
    "T_2D = torch.tensor([  \n",
    "    [[1,1,0,1,1],[2,2,0,2,2],[3,3,0,3,3],[4,4,0,4,4],[5,5,0,5,5]], \n",
    "    [[1,0,1,0,1],[2,0,2,0,2],[3,0,3,0,3],[4,0,4,0,4],[5,0,5,0,5]],\n",
    "    [[0,1,0,1,0],[0,2,0,2,0],[0,3,0,3,0],[0,4,0,4,0],[0,5,0,5,0]]\n",
    "], dtype = torch.float)\n",
    "T_2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (nlp)",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
